{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(img,noise_type=\"gaussian\"):\n",
    "  \n",
    "  row,col=28,28\n",
    "  \n",
    "  if noise_type==\"gaussian\":\n",
    "    mean=0\n",
    "    var=10\n",
    "    sigma=var**.5\n",
    "    noise=np.random.normal(-5.9,5.9,img.shape)\n",
    "    noise=noise.reshape(row,col)\n",
    "    img=img+noise\n",
    "    return img\n",
    "\n",
    "  if noise_type==\"speckle\":\n",
    "    noise=np.random.randn(row,col)\n",
    "    noise=noise.reshape(row,col)\n",
    "    img=img+img*noise\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        #encoder\n",
    "        self.e1 = nn.Linear(784,28)\n",
    "        self.e2 = nn.Linear(28,250)\n",
    "        self.e3 = nn.Linear()\n",
    "        \n",
    "        #Latent View\n",
    "        self.lv = nn.Linear(250,10)\n",
    "        \n",
    "        #Decoder\n",
    "        self.d1 = nn.Linear(10,250)\n",
    "        self.d2 = nn.Linear(250,500)\n",
    "        \n",
    "        self.output_layer = nn.Linear(500,784)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.sigmoid(self.e1(x))\n",
    "        x = F.sigmoid(self.e2(x))\n",
    "        \n",
    "        x = torch.sigmoid(self.lv(x))\n",
    "        \n",
    "        x = F.sigmoid(self.d1(x))\n",
    "        x = F.sigmoid(self.d2(x))\n",
    "        \n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'in_features' and 'out_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-ed1e098bb6cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mae\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-b438dbed42fa>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#Latent View\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'in_features' and 'out_features'"
     ]
    }
   ],
   "source": [
    "ae = AutoEncoder()\n",
    "print(ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CDAutoEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional denoising autoencoder layer for stacked autoencoders.\n",
    "    This module is automatically trained when in model.training is True.\n",
    "\n",
    "    Args:\n",
    "        input_size: The number of features in the input\n",
    "        output_size: The number of features to output\n",
    "        stride: Stride of the convolutional layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, output_size, stride):\n",
    "        super(CDAutoEncoder, self).__init__()\n",
    "\n",
    "        self.forward_pass = nn.Sequential(\n",
    "            nn.Conv2d(input_size, output_size, kernel_size=2, stride=stride, padding=0),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.backward_pass = nn.Sequential(\n",
    "            nn.ConvTranspose2d(output_size, input_size, kernel_size=2, stride=2, padding=0), \n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = torch.optim.SGD(self.parameters(), lr=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Train each autoencoder individually\n",
    "        x = x.detach()\n",
    "        # Add noise, but use the original lossless input as the target.\n",
    "        x_noisy = x * (Variable(x.data.new(x.size()).normal_(0, 0.1)) > -.1).type_as(x)\n",
    "        y = self.forward_pass(x_noisy)\n",
    "\n",
    "        if self.training:\n",
    "            x_reconstruct = self.backward_pass(y)\n",
    "            #loss = self.criterion(x_reconstruct, Variable(x.data, requires_grad=False))\n",
    "            loss = nn.CrossEntropyLoss()\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "        return y.detach()\n",
    "\n",
    "    def reconstruct(self, x):\n",
    "        return self.backward_pass(x)\n",
    "\n",
    "\n",
    "class StackedAutoEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A stacked autoencoder made from the convolutional denoising autoencoders above.\n",
    "    Each autoencoder is trained independently and at the same time.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(StackedAutoEncoder, self).__init__()\n",
    "\n",
    "        self.ae1 = CDAutoEncoder(500, 500, 500)\n",
    "        self.ae2 = CDAutoEncoder(500, 500, 500)\n",
    "        self.ae3 = CDAutoEncoder(500, 500, 500)\n",
    "\n",
    "    def forward(self, x):\n",
    "        a1 = self.ae1(x)\n",
    "        a2 = self.ae2(a1)\n",
    "        a3 = self.ae3(a2)\n",
    "\n",
    "        if self.training:\n",
    "            return a3\n",
    "\n",
    "        else:\n",
    "            return a3, self.reconstruct(a3)\n",
    "\n",
    "    def reconstruct(self, x):\n",
    "            a2_reconstruct = self.ae3.reconstruct(x)\n",
    "            a1_reconstruct = self.ae2.reconstruct(a2_reconstruct)\n",
    "            x_reconstruct = self.ae1.reconstruct(a1_reconstruct)\n",
    "            return x_reconstruct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class FeatureDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, file_name):\n",
    "        \n",
    "        # read csv and load data from rows into variables\n",
    "        file_out = pd.read_csv(file_name)\n",
    "        x = file_out.iloc[1:200, 1:200].values\n",
    "        y = file_out.iloc[1:200, 1:200].values\n",
    "        \n",
    "        # Feature Scaling \n",
    "        #sc = StandardScaler()\n",
    "        #x_train = sc.fit_transform(x)\n",
    "        \n",
    "        x_train = x\n",
    "        y_train = y\n",
    "        \n",
    "        # Convert to torch tensors\n",
    "        self.X_train = torch.tensor(x_train)\n",
    "        self.y_train = torch.tensor(y_train)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_train[idx], self.y_train[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('patient_vecs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>EXPIRE_FLAG</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>DIAGNOSIS</th>\n",
       "      <th>HAS_CHARTEVENTS_DATA</th>\n",
       "      <th>DRUG</th>\n",
       "      <th>FORMULARY_DRUG_CD</th>\n",
       "      <th>age</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>['M']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>['ASIAN']</td>\n",
       "      <td>['NEWBORN']</td>\n",
       "      <td>[1]</td>\n",
       "      <td>['NEO*IV*Gentamicin', 'Syringe (Neonatal) *D5W...</td>\n",
       "      <td>['GENT10I', 'NEOSYRD5W', 'AMP500I', 'AMPVL']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>['V3001', 'V053', 'V290']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>['F']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>['WHITE']</td>\n",
       "      <td>['FEVER,DEHYDRATION,FAILURE TO THRIVE']</td>\n",
       "      <td>[1]</td>\n",
       "      <td>['Iso-Osmotic Dextrose', 'Insulin', 'Benzonata...</td>\n",
       "      <td>['VANCOBASE', 'GLAR100I', 'BENZ100', 'INSULIN'...</td>\n",
       "      <td>[47]</td>\n",
       "      <td>['042', '1363', '7994', '2763', '7907', '5715'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>['F']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>['WHITE']</td>\n",
       "      <td>['CHRONIC RENAL FAILURE/SDA']</td>\n",
       "      <td>[1]</td>\n",
       "      <td>['Tacrolimus', 'Warfarin', 'Heparin Sodium', '...</td>\n",
       "      <td>['TACR1', 'WARF5', 'HEPAPREMIX', 'HEPBASE', 'F...</td>\n",
       "      <td>[65]</td>\n",
       "      <td>['40391', '4440', '9972', '2766', '2767', '285...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>['M']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>['WHITE']</td>\n",
       "      <td>['NEWBORN']</td>\n",
       "      <td>[1]</td>\n",
       "      <td>['Send 500mg Vial', 'NEO*IV*Gentamicin', 'NEO*...</td>\n",
       "      <td>['AMPVL', 'GENT10I', 'NAMP500I', 'NEOSYRD5W']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>['V3001', '7706', '7746', 'V290', 'V502', 'V053']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>['M']</td>\n",
       "      <td>[1]</td>\n",
       "      <td>['UNKNOWN/NOT SPECIFIED']</td>\n",
       "      <td>['HEMORRHAGIC CVA']</td>\n",
       "      <td>[1]</td>\n",
       "      <td>['SW', 'Labetalol HCl', 'Potassium Chloride', ...</td>\n",
       "      <td>['KCLBASE', 'LABE100I', 'KCL20P', 'D5W250', 'N...</td>\n",
       "      <td>[41]</td>\n",
       "      <td>['431', '5070', '4280', '5849', '2765', '4019']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID GENDER EXPIRE_FLAG                  ETHNICITY  \\\n",
       "0           2  ['M']         [0]                  ['ASIAN']   \n",
       "1           4  ['F']         [0]                  ['WHITE']   \n",
       "2           6  ['F']         [0]                  ['WHITE']   \n",
       "3           8  ['M']         [0]                  ['WHITE']   \n",
       "4           9  ['M']         [1]  ['UNKNOWN/NOT SPECIFIED']   \n",
       "\n",
       "                                 DIAGNOSIS HAS_CHARTEVENTS_DATA  \\\n",
       "0                              ['NEWBORN']                  [1]   \n",
       "1  ['FEVER,DEHYDRATION,FAILURE TO THRIVE']                  [1]   \n",
       "2            ['CHRONIC RENAL FAILURE/SDA']                  [1]   \n",
       "3                              ['NEWBORN']                  [1]   \n",
       "4                      ['HEMORRHAGIC CVA']                  [1]   \n",
       "\n",
       "                                                DRUG  \\\n",
       "0  ['NEO*IV*Gentamicin', 'Syringe (Neonatal) *D5W...   \n",
       "1  ['Iso-Osmotic Dextrose', 'Insulin', 'Benzonata...   \n",
       "2  ['Tacrolimus', 'Warfarin', 'Heparin Sodium', '...   \n",
       "3  ['Send 500mg Vial', 'NEO*IV*Gentamicin', 'NEO*...   \n",
       "4  ['SW', 'Labetalol HCl', 'Potassium Chloride', ...   \n",
       "\n",
       "                                   FORMULARY_DRUG_CD   age  \\\n",
       "0       ['GENT10I', 'NEOSYRD5W', 'AMP500I', 'AMPVL']   [0]   \n",
       "1  ['VANCOBASE', 'GLAR100I', 'BENZ100', 'INSULIN'...  [47]   \n",
       "2  ['TACR1', 'WARF5', 'HEPAPREMIX', 'HEPBASE', 'F...  [65]   \n",
       "3      ['AMPVL', 'GENT10I', 'NAMP500I', 'NEOSYRD5W']   [0]   \n",
       "4  ['KCLBASE', 'LABE100I', 'KCL20P', 'D5W250', 'N...  [41]   \n",
       "\n",
       "                                           ICD9_CODE  \n",
       "0                          ['V3001', 'V053', 'V290']  \n",
       "1  ['042', '1363', '7994', '2763', '7907', '5715'...  \n",
       "2  ['40391', '4440', '9972', '2766', '2767', '285...  \n",
       "3  ['V3001', '7706', '7746', 'V290', 'V502', 'V053']  \n",
       "4    ['431', '5070', '4280', '5849', '2765', '4019']  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>EXPIRE_FLAG</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>HAS_CHARTEVENTS_DATA</th>\n",
       "      <th>DRUG</th>\n",
       "      <th>FORMULARY_DRUG_CD</th>\n",
       "      <th>age</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>['M']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>['ASIAN']</td>\n",
       "      <td>[1]</td>\n",
       "      <td>['NEO*IV*Gentamicin', 'Syringe (Neonatal) *D5W...</td>\n",
       "      <td>['GENT10I', 'NEOSYRD5W', 'AMP500I', 'AMPVL']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>['V3001', 'V053', 'V290']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>['F']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>['WHITE']</td>\n",
       "      <td>[1]</td>\n",
       "      <td>['Iso-Osmotic Dextrose', 'Insulin', 'Benzonata...</td>\n",
       "      <td>['VANCOBASE', 'GLAR100I', 'BENZ100', 'INSULIN'...</td>\n",
       "      <td>[47]</td>\n",
       "      <td>['042', '1363', '7994', '2763', '7907', '5715'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>['F']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>['WHITE']</td>\n",
       "      <td>[1]</td>\n",
       "      <td>['Tacrolimus', 'Warfarin', 'Heparin Sodium', '...</td>\n",
       "      <td>['TACR1', 'WARF5', 'HEPAPREMIX', 'HEPBASE', 'F...</td>\n",
       "      <td>[65]</td>\n",
       "      <td>['40391', '4440', '9972', '2766', '2767', '285...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>['M']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>['WHITE']</td>\n",
       "      <td>[1]</td>\n",
       "      <td>['Send 500mg Vial', 'NEO*IV*Gentamicin', 'NEO*...</td>\n",
       "      <td>['AMPVL', 'GENT10I', 'NAMP500I', 'NEOSYRD5W']</td>\n",
       "      <td>[0]</td>\n",
       "      <td>['V3001', '7706', '7746', 'V290', 'V502', 'V053']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>['M']</td>\n",
       "      <td>[1]</td>\n",
       "      <td>['UNKNOWN/NOT SPECIFIED']</td>\n",
       "      <td>[1]</td>\n",
       "      <td>['SW', 'Labetalol HCl', 'Potassium Chloride', ...</td>\n",
       "      <td>['KCLBASE', 'LABE100I', 'KCL20P', 'D5W250', 'N...</td>\n",
       "      <td>[41]</td>\n",
       "      <td>['431', '5070', '4280', '5849', '2765', '4019']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID GENDER EXPIRE_FLAG                  ETHNICITY  \\\n",
       "0           2  ['M']         [0]                  ['ASIAN']   \n",
       "1           4  ['F']         [0]                  ['WHITE']   \n",
       "2           6  ['F']         [0]                  ['WHITE']   \n",
       "3           8  ['M']         [0]                  ['WHITE']   \n",
       "4           9  ['M']         [1]  ['UNKNOWN/NOT SPECIFIED']   \n",
       "\n",
       "  HAS_CHARTEVENTS_DATA                                               DRUG  \\\n",
       "0                  [1]  ['NEO*IV*Gentamicin', 'Syringe (Neonatal) *D5W...   \n",
       "1                  [1]  ['Iso-Osmotic Dextrose', 'Insulin', 'Benzonata...   \n",
       "2                  [1]  ['Tacrolimus', 'Warfarin', 'Heparin Sodium', '...   \n",
       "3                  [1]  ['Send 500mg Vial', 'NEO*IV*Gentamicin', 'NEO*...   \n",
       "4                  [1]  ['SW', 'Labetalol HCl', 'Potassium Chloride', ...   \n",
       "\n",
       "                                   FORMULARY_DRUG_CD   age  \\\n",
       "0       ['GENT10I', 'NEOSYRD5W', 'AMP500I', 'AMPVL']   [0]   \n",
       "1  ['VANCOBASE', 'GLAR100I', 'BENZ100', 'INSULIN'...  [47]   \n",
       "2  ['TACR1', 'WARF5', 'HEPAPREMIX', 'HEPBASE', 'F...  [65]   \n",
       "3      ['AMPVL', 'GENT10I', 'NAMP500I', 'NEOSYRD5W']   [0]   \n",
       "4  ['KCLBASE', 'LABE100I', 'KCL20P', 'D5W250', 'N...  [41]   \n",
       "\n",
       "                                           ICD9_CODE  \n",
       "0                          ['V3001', 'V053', 'V290']  \n",
       "1  ['042', '1363', '7994', '2763', '7907', '5715'...  \n",
       "2  ['40391', '4440', '9972', '2766', '2767', '285...  \n",
       "3  ['V3001', '7706', '7746', 'V290', 'V502', 'V053']  \n",
       "4    ['431', '5070', '4280', '5849', '2765', '4019']  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39363"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/nicenoize/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\", line 2646, in get_loc\n    return self._engine.get_loc(key)\n  File \"pandas/_libs/index.pyx\", line 111, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 138, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1618, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1626, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 34709\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/nicenoize/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Users/nicenoize/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/nicenoize/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/nicenoize/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\", line 2800, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"/Users/nicenoize/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\", line 2648, in get_loc\n    return self._engine.get_loc(self._maybe_cast_indexer(key))\n  File \"pandas/_libs/index.pyx\", line 111, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 138, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1618, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1626, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 34709\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-791be3e72fee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#.cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#.cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/nicenoize/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\", line 2646, in get_loc\n    return self._engine.get_loc(key)\n  File \"pandas/_libs/index.pyx\", line 111, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 138, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1618, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1626, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 34709\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/nicenoize/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Users/nicenoize/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/nicenoize/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/nicenoize/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\", line 2800, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"/Users/nicenoize/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\", line 2648, in get_loc\n    return self._engine.get_loc(self._maybe_cast_indexer(key))\n  File \"pandas/_libs/index.pyx\", line 111, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 138, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1618, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1626, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 34709\n"
     ]
    }
   ],
   "source": [
    "for i in enumerate(dataloader):\n",
    "        img, target = data\n",
    "        target = Variable(target) #.cuda()\n",
    "        img = Variable(img) #.cuda()\n",
    "        features = model(img).detach()\n",
    "        prediction = classifier(features.view(features.size(0), -1))\n",
    "        loss = criterion(prediction, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pred = prediction.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "#import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "#from torchvision import transforms\n",
    "#from torchvision.datasets import MNIST, CIFAR10\n",
    "#from torchvision.utils import save_image\n",
    "\n",
    "#from model import StackedAutoEncoder\n",
    "\n",
    "num_epochs = 1000\n",
    "batch_size = 128\n",
    "\n",
    "#dataset = CIFAR10('../data/cifar10/', transform=img_transform)\n",
    "#dataset = FeatureDataset('patient_vecs.csv')\n",
    "\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "model = StackedAutoEncoder() #.cuda()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    if epoch % 10 == 0:\n",
    "        # Test the quality of our features with a randomly initialzed linear classifier.\n",
    "        classifier = nn.Linear(512 * 16, 10) #.cuda()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
    "\n",
    "    model.train()\n",
    "    total_time = time.time()\n",
    "    correct = 0\n",
    "    for i, data in enumerate(dataloader):\n",
    "        img, target = data\n",
    "        target = Variable(target) #.cuda()\n",
    "        img = Variable(img) #.cuda()\n",
    "        features = model(img).detach()\n",
    "        prediction = classifier(features.view(features.size(0), -1))\n",
    "        loss = criterion(prediction, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pred = prediction.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    total_time = time.time() - total_time\n",
    "\n",
    "    model.eval()\n",
    "    img, _ = data\n",
    "    img = Variable(img) #.cuda()\n",
    "    features, x_reconstructed = model(img)\n",
    "    reconstruction_loss = torch.mean((x_reconstructed.data - img.data)**2)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Saving epoch {}\".format(epoch))\n",
    "        orig = to_img(img.cpu().data)\n",
    "        save_image(orig, './imgs/orig_{}.png'.format(epoch))\n",
    "        pic = to_img(x_reconstructed.cpu().data)\n",
    "        save_image(pic, './imgs/reconstruction_{}.png'.format(epoch))\n",
    "\n",
    "    print(\"Epoch {} complete\\tTime: {:.4f}s\\t\\tLoss: {:.4f}\".format(epoch, total_time, reconstruction_loss))\n",
    "    print(\"Feature Statistics\\tMean: {:.4f}\\t\\tMax: {:.4f}\\t\\tSparsity: {:.4f}%\".format(\n",
    "        torch.mean(features.data), torch.max(features.data), torch.sum(features.data == 0.0)*100 / features.data.numel())\n",
    "    )\n",
    "    print(\"Linear classifier performance: {}/{} = {:.2f}%\".format(correct, len(dataloader)*batch_size, 100*float(correct) / (len(dataloader)*batch_size)))\n",
    "    print(\"=\"*80)\n",
    "\n",
    "torch.save(model.state_dict(), './CDAE.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f3eb2a1c56bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "for idx in enumerate(dataset):\n",
    "    print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'emotion'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'emotion'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-dc8ae3b5b9e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomDatasetFromCSV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'patient_vecs.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-dc8ae3b5b9e3>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, csv_path, transform)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emotion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m48\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m48\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'emotion'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "class CustomDatasetFromCSV(Dataset):\n",
    "    def __init__(self, csv_path, transform=None):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "         self.height = 48\n",
    "        self.width = 48\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # This method should return only 1 sample and label \n",
    "        # (according to \"index\"), not the whole dataset\n",
    "        # So probably something like this for you:\n",
    "        pixel_sequence = self.data['pixels'][index]\n",
    "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "        face = np.asarray(face).reshape(self.width, self.height)\n",
    "        face = cv2.resize(face.astype('uint8'), (self.width, self.height))\n",
    "        label = self.labels[index]\n",
    "\n",
    "        return face, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "dataset = CustomDatasetFromCSV('patient_vecs.csv')\n",
    "batch_size = 16\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
