{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas_gbq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not determine project ID and one was not supplied.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b5bc600325be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# The credentials and project_id arguments can be omitted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas_gbq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_gbq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SELECT * FROM `mimiciii_clinical.patients`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas_gbq/gbq.py\u001b[0m in \u001b[0;36mread_gbq\u001b[0;34m(query, project_id, index_col, col_order, reauth, auth_local_webserver, dialect, location, configuration, credentials, use_bqstorage_api, max_results, verbose, private_key, progress_bar_type)\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m         \u001b[0mprivate_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprivate_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m         \u001b[0muse_bqstorage_api\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_bqstorage_api\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m     )\n\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas_gbq/gbq.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, project_id, reauth, private_key, auth_local_webserver, dialect, location, credentials, use_bqstorage_api)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             raise ValueError(\n\u001b[0;32m--> 362\u001b[0;31m                 \u001b[0;34m\"Could not determine project ID and one was not supplied.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m             )\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not determine project ID and one was not supplied."
     ]
    }
   ],
   "source": [
    "pandas_gbq.context.project = \"deeppatient\"\n",
    "\n",
    "# The credentials and project_id arguments can be omitted.\n",
    "df = pandas_gbq.read_gbq(\"SELECT * FROM `mimiciii_clinical.patients`\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(img,noise_type=\"gaussian\"):\n",
    "  \n",
    "  row,col=28,28\n",
    "  \n",
    "  if noise_type==\"gaussian\":\n",
    "    mean=0\n",
    "    var=10\n",
    "    sigma=var**.5\n",
    "    noise=np.random.normal(-5.9,5.9,img.shape)\n",
    "    noise=noise.reshape(row,col)\n",
    "    img=img+noise\n",
    "    return img\n",
    "\n",
    "  if noise_type==\"speckle\":\n",
    "    noise=np.random.randn(row,col)\n",
    "    noise=noise.reshape(row,col)\n",
    "    img=img+img*noise\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        #encoder\n",
    "        self.e1 = nn.Linear(784,28)\n",
    "        self.e2 = nn.Linear(28,250)\n",
    "        self.e3 = nn.Linear()\n",
    "        \n",
    "        #Latent View\n",
    "        self.lv = nn.Linear(250,10)\n",
    "        \n",
    "        #Decoder\n",
    "        self.d1 = nn.Linear(10,250)\n",
    "        self.d2 = nn.Linear(250,500)\n",
    "        \n",
    "        self.output_layer = nn.Linear(500,784)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.sigmoid(self.e1(x))\n",
    "        x = F.sigmoid(self.e2(x))\n",
    "        \n",
    "        x = torch.sigmoid(self.lv(x))\n",
    "        \n",
    "        x = F.sigmoid(self.d1(x))\n",
    "        x = F.sigmoid(self.d2(x))\n",
    "        \n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = AutoEncoder()\n",
    "print(ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CDAutoEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional denoising autoencoder layer for stacked autoencoders.\n",
    "    This module is automatically trained when in model.training is True.\n",
    "\n",
    "    Args:\n",
    "        input_size: The number of features in the input\n",
    "        output_size: The number of features to output\n",
    "        stride: Stride of the convolutional layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, output_size, stride):\n",
    "        super(CDAutoEncoder, self).__init__()\n",
    "\n",
    "        self.forward_pass = nn.Sequential(\n",
    "            nn.Conv2d(input_size, output_size, kernel_size=2, stride=stride, padding=0),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.backward_pass = nn.Sequential(\n",
    "            nn.ConvTranspose2d(output_size, input_size, kernel_size=2, stride=2, padding=0), \n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = torch.optim.SGD(self.parameters(), lr=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Train each autoencoder individually\n",
    "        x = x.detach()\n",
    "        # Add noise, but use the original lossless input as the target.\n",
    "        x_noisy = x * (Variable(x.data.new(x.size()).normal_(0, 0.1)) > -.1).type_as(x)\n",
    "        y = self.forward_pass(x_noisy)\n",
    "\n",
    "        if self.training:\n",
    "            x_reconstruct = self.backward_pass(y)\n",
    "            #loss = self.criterion(x_reconstruct, Variable(x.data, requires_grad=False))\n",
    "            loss = nn.CrossEntropyLoss()\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "        return y.detach()\n",
    "\n",
    "    def reconstruct(self, x):\n",
    "        return self.backward_pass(x)\n",
    "\n",
    "\n",
    "class StackedAutoEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A stacked autoencoder made from the convolutional denoising autoencoders above.\n",
    "    Each autoencoder is trained independently and at the same time.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(StackedAutoEncoder, self).__init__()\n",
    "\n",
    "        self.ae1 = CDAutoEncoder(500)\n",
    "        self.ae2 = CDAutoEncoder(500)\n",
    "        self.ae3 = CDAutoEncoder(500)\n",
    "\n",
    "    def forward(self, x):\n",
    "        a1 = self.ae1(x)\n",
    "        a2 = self.ae2(a1)\n",
    "        a3 = self.ae3(a2)\n",
    "\n",
    "        if self.training:\n",
    "            return a3\n",
    "\n",
    "        else:\n",
    "            return a3, self.reconstruct(a3)\n",
    "\n",
    "    def reconstruct(self, x):\n",
    "            a2_reconstruct = self.ae3.reconstruct(x)\n",
    "            a1_reconstruct = self.ae2.reconstruct(a2_reconstruct)\n",
    "            x_reconstruct = self.ae1.reconstruct(a1_reconstruct)\n",
    "            return x_reconstruct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
